# Steel Defect Classifier

Este projeto tem como objetivo desenvolver um sistema de detecÃ§Ã£o automÃ¡tica de falhas em peÃ§as de aÃ§o, utilizando tÃ©cnicas de ciÃªncia de dados e aprendizado de mÃ¡quina. O sistema Ã© acessÃ­vel via uma aplicaÃ§Ã£o interativa construÃ­da com Streamlit.

## ğŸ” Problema

A inspeÃ§Ã£o de falhas em processos industriais Ã© uma tarefa crÃ­tica. Este projeto busca aplicar modelos supervisionados de aprendizado de mÃ¡quina para prever diferentes tipos de falhas com base em variÃ¡veis do processo produtivo, contribuindo para reduÃ§Ã£o de retrabalho e aumento de eficiÃªncia.

## ğŸ› ï¸ Tecnologias Utilizadas

Python 3.11

Pandas, NumPy

Scikit-learn

Seaborn, Matplotlib

Streamlit

RandomForestClassifier com estratÃ©gia One-vs-Rest

## ğŸ“ Estrutura do Projeto

```bash
steel-defect-classifier/
â”œâ”€â”€ data/ # Conjuntos de dados (raw e processed)
â”œâ”€â”€ models/ # Modelos treinados (pkl)
â”œâ”€â”€ results/ # MÃ©tricas e grÃ¡ficos
â”œâ”€â”€ figs_ovr/ # Imagens de mÃ©tricas e matrizes de confusÃ£o
â”œâ”€â”€ src/
â”‚ â””â”€â”€ utils/ # Scripts auxiliares
â”œâ”€â”€ app.py # AplicaÃ§Ã£o principal em Streamlit
â”œâ”€â”€ docs/ # Imagens e materiais para documentaÃ§Ã£o
â””â”€â”€ README.md
```

ğŸš€ Como Executar Localmente

Clone este repositÃ³rio:

```bash
git clone https://github.com/dandenardi/steel-defect-classifier.git
cd steel-defect-classifier
```

Crie e ative o ambiente virtual conda:

```bash
conda env create -f environment.yml
conda activate steell-classfier-env
```

### Execute o app:

```bash
streamlit run app.py
```

## ğŸ“ˆ Resultados

- Utilizou-se Random Forest com estratÃ©gia One-vs-Rest para multirrÃ³tulo.

- Dados divididos em treino/teste com avaliaÃ§Ã£o por mÃ©tricas de precisÃ£o, recall, F1-score e matriz de confusÃ£o.

- Classes com maior representaÃ§Ã£o obtiveram melhor performance.

- Falhas com menos dados mostraram menor desempenho, indicando necessidade de balanceamento.

## âœ… PrÃ³ximos Passos

- Aumentar a amostra de falhas menos frequentes.

- Testar tÃ©cnicas de balanceamento como SMOTE.

- Avaliar modelos alternativos como XGBoost e LightGBM.

- Otimizar hiperparÃ¢metros com GridSearch ou RandomSearch.

âœï¸ Autor
Daniel do Amaral Denardi - @dandenardi
